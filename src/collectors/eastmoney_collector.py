import requests
import json
import time
from datetime import datetime
from typing import List, Dict, Optional
import hashlib


class EastMoneyCollector:
    """ä¸œæ–¹è´¢å¯Œå¿«è®¯é‡‡é›†å™¨ï¼ˆä¼˜åŒ–ç‰ˆ - ç›´æ¥åœ¨æ¶ˆæ¯ä¸­æ˜¾ç¤ºå†…å®¹ï¼‰"""

    def __init__(self):
        # çœŸå®APIåœ°å€
        self.base_url = "https://np-weblist.eastmoney.com/comm/web/getFastNewsList"

        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://kuaixun.eastmoney.com/',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        }

        # APIå‚æ•°
        self.base_params = {
            'client': 'web',
            'biz': 'web_724',
            'fastColumn': '102',  # å¿«è®¯æ ç›®ID
            'pageSize': 20,
            'sortEnd': int(time.time() * 1000000),
            'req_trace': int(time.time() * 1000),
            '_': int(time.time() * 1000),
            'callback': f'jQuery_{int(time.time() * 1000)}'
        }

    def fetch_news(self, page_size: int = 20) -> Optional[List[Dict]]:
        """
        è·å–ä¸œæ–¹è´¢å¯Œå¿«è®¯æ–°é—»ï¼ˆä¼˜åŒ–ç‰ˆï¼‰

        Args:
            page_size: æ¯é¡µæ•°é‡

        Returns:
            ç»“æ„åŒ–çš„æ–°é—»åˆ—è¡¨ï¼ŒåŒ…å«å®Œæ•´å†…å®¹
        """
        try:
            # æ›´æ–°å‚æ•°
            params = self.base_params.copy()
            params['pageSize'] = page_size
            params['sortEnd'] = int(time.time() * 1000000)
            params['_'] = int(time.time() * 1000)
            params['callback'] = f'jQuery_{int(time.time() * 1000)}'

            print(f"æ­£åœ¨æŠ“å–å¿«è®¯ï¼Œæ¯é¡µ {page_size} æ¡...")

            response = requests.get(
                self.base_url,
                params=params,
                headers=self.headers,
                timeout=15
            )

            response.raise_for_status()

            # å¤„ç†JSONPå“åº”
            raw_text = response.text
            json_start = raw_text.find('(')
            json_end = raw_text.rfind(')')

            if json_start != -1 and json_end != -1:
                json_str = raw_text[json_start + 1:json_end]
                data = json.loads(json_str)

                # è§£ææ–°é—»æ•°æ®
                news_list = self._parse_news_data(data)
                return news_list
            else:
                print(f"å“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONPæ ¼å¼")
                return None

        except requests.exceptions.RequestException as e:
            print(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
            return None
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {raw_text[:500]}...")
            return None
        except Exception as e:
            print(f"æœªçŸ¥é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _parse_news_data(self, data: Dict) -> List[Dict]:
        """
        è§£æAPIè¿”å›çš„æ–°é—»æ•°æ®
        """
        news_items = []

        # æ ¹æ®APIç»“æ„æŸ¥æ‰¾æ–°é—»æ•°æ®
        if isinstance(data, dict) and data.get('code') == "1":
            # ä»fastNewsListè·å–æ•°æ®
            news_data = data.get('data', {}).get('fastNewsList', [])

            if isinstance(news_data, list):
                print(f"å¼€å§‹è§£æ {len(news_data)} æ¡æ–°é—»...")

                for i, item in enumerate(news_data):
                    try:
                        # è§£æå•æ¡æ–°é—»
                        news_item = self._parse_single_news(item)
                        if news_item and news_item.get('title'):
                            news_items.append(news_item)

                            # åªæ˜¾ç¤ºå‰3æ¡ä½œä¸ºç¤ºä¾‹
                            if i < 3:
                                print(f"  ç¤ºä¾‹{i + 1}: {news_item['title'][:50]}...")

                    except Exception as e:
                        print(f"è§£æç¬¬{i + 1}æ¡æ–°é—»å¤±è´¥: {e}")
                        continue

        return news_items

    def _parse_single_news(self, item) -> Dict:
        """è§£æå•æ¡æ–°é—» - ä¼˜åŒ–ç‰ˆï¼ˆåŒ…å«å®Œæ•´å†…å®¹ï¼‰"""
        try:
            # ä¸ºæ–°é—»ç”Ÿæˆå”¯ä¸€ID
            unique_str = f"{item.get('title', '')}_{item.get('showTime', '')}_{item.get('code', '')}"
            news_id = hashlib.md5(unique_str.encode()).hexdigest()[:16]

            # æå–å…³é”®ä¿¡æ¯
            title = item.get('title', '').strip()
            summary = item.get('summary', '').strip()
            code = item.get('code', '')
            show_time = item.get('showTime', '')

            # ä½¿ç”¨æ‘˜è¦ä½œä¸ºå†…å®¹ï¼Œå¦‚æœæ²¡æœ‰æ‘˜è¦åˆ™ä½¿ç”¨æ ‡é¢˜
            content = summary if summary else title

            # åŸºç¡€æ–°é—»ç»“æ„
            news_item = {
                'id': news_id,
                'code': code,
                'title': title,
                'summary': summary,
                'content': content,  # ç®€çŸ­å†…å®¹
                'full_content': content,  # å®Œæ•´å†…å®¹ï¼ˆæ‘˜è¦ï¼‰
                'raw_data': item  # ä¿å­˜åŸå§‹æ•°æ®
            }

            # æ—¶é—´å­—æ®µ
            if show_time:
                news_item['time'] = show_time
                news_item['publish_time'] = show_time
            else:
                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                news_item['time'] = current_time
                news_item['publish_time'] = current_time

            # æ¥æºå¤„ç†
            source = item.get('mediaName', item.get('source', ''))
            if not source:
                source = 'ä¸œæ–¹è´¢å¯Œå¿«è®¯'
            news_item['source'] = source.strip()

            # URLï¼ˆè™½ç„¶å¯èƒ½æ— æ³•åœ¨é’‰é’‰ä¸­è®¿é—®ï¼Œä½†ä»ä¿ç•™ï¼‰
            news_item[
                'url'] = f"https://kuaixun.eastmoney.com/news/{code}.html" if code else "https://kuaixun.eastmoney.com/"

            # åˆ†ç±»
            news_item['category'] = self._infer_category(item)

            # é‡è¦æ€§è¯„åˆ†
            news_item['importance'] = self._calculate_importance(item)

            # æƒ…æ„Ÿåˆ†æ
            news_item['sentiment'] = self._judge_sentiment(title + summary)

            # è‚¡ç¥¨å…³è”
            stock_list = item.get('stockList', [])
            if stock_list and isinstance(stock_list, list):
                news_item['related_stocks'] = stock_list
                news_item['has_stock_mention'] = True
            else:
                news_item['related_stocks'] = []
                news_item['has_stock_mention'] = False

            # äº’åŠ¨æ•°æ®
            news_item['comment_count'] = item.get('pinglun_Num', 0)
            news_item['share_count'] = item.get('share', 0)

            # æ¸…ç†å’ŒéªŒè¯
            self._clean_news_item(news_item)

            return news_item

        except Exception as e:
            print(f"è§£æå•æ¡æ–°é—»å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            # è¿”å›æœ€å°å¯ç”¨çš„æ–°é—»å¯¹è±¡
            return {
                'id': hashlib.md5(str(time.time()).encode()).hexdigest()[:16],
                'title': str(item.get('title', 'è§£æå¤±è´¥'))[:200],
                'content': str(item)[:500],
                'full_content': str(item)[:500],
                'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'source': 'è§£æå¼‚å¸¸',
                'url': '',
                'category': 'å…¶ä»–',
                'importance': 5,
                'sentiment': 'neutral'
            }

    def _infer_category(self, item) -> str:
        """æ ¹æ®å†…å®¹æ¨æ–­æ–°é—»åˆ†ç±»"""
        title = item.get('title', '').lower()
        summary = item.get('summary', '').lower()

        # å…³é”®è¯åŒ¹é…åˆ†ç±»
        category_keywords = {
            'å®è§‚': ['gdp', 'cpi', 'ppi', 'é€šèƒ€', 'é€šç¼©', 'è´§å¸æ”¿ç­–', 'è´¢æ”¿æ”¿ç­–', 'å¤®è¡Œ', 'åˆ©ç‡', 'å­˜æ¬¾å‡†å¤‡é‡‘'],
            'è‚¡å¸‚': ['aè‚¡', 'æ²ªæŒ‡', 'æ·±æŒ‡', 'åˆ›ä¸šæ¿', 'ç§‘åˆ›æ¿', 'æ¶¨åœ', 'è·Œåœ', 'å¤§ç›˜', 'æŒ‡æ•°', 'è‚¡ç¥¨', 'è‚¡ä»·'],
            'å€ºåˆ¸': ['å›½å€º', 'åœ°æ–¹å€º', 'åŸæŠ•å€º', 'ä¼ä¸šå€º', 'å¯è½¬å€º', 'å€ºåˆ¸', 'æ”¶ç›Šç‡'],
            'æœŸè´§': ['æœŸè´§', 'åŸæ²¹', 'é»„é‡‘', 'ç™½é“¶', 'é“œ', 'é“', 'èºçº¹é’¢', 'é“çŸ¿çŸ³'],
            'å¤–æ±‡': ['ç¾å…ƒ', 'äººæ°‘å¸', 'æ¬§å…ƒ', 'è‹±é•‘', 'æ—¥å…ƒ', 'æ±‡ç‡', 'å¤–æ±‡'],
            'å•†å“': ['åŸæ²¹', 'é»„é‡‘', 'ç™½é“¶', 'é“œ', 'å¤§å®—å•†å“', 'ç°è´§'],
            'ç†è´¢': ['é“¶è¡Œç†è´¢', 'ä¿¡æ‰˜', 'ä¿é™©', 'åŸºé‡‘', 'èµ„ç®¡', 'ç†è´¢äº§å“'],
            'æˆ¿åœ°äº§': ['æˆ¿ä»·', 'æˆ¿åœ°äº§', 'æ¥¼å¸‚', 'æˆ¿ä¼', 'åœŸåœ°', 'æ‹å–'],
            'å…¬å¸': ['è´¢æŠ¥', 'ä¸šç»©', 'è¥æ”¶', 'å‡€åˆ©æ¶¦', 'åˆ†çº¢', 'å›è´­', 'st', 'ipo'],
            'è¡Œä¸š': ['è¡Œä¸š', 'æ¿å—', 'æ¦‚å¿µ', 'äº§ä¸šé“¾', 'äº§èƒ½', 'äº§é‡'],
            'å›½é™…': ['ç¾è”å‚¨', 'æ¬§å¤®è¡Œ', 'åŠ æ¯', 'é™æ¯', 'é€šèƒ€', 'è´¸æ˜“æˆ˜'],
            'æ”¿ç­–': ['æ”¿ç­–', 'æ³•è§„', 'æ¡ä¾‹', 'ç›‘ç®¡', 'æ£€æŸ¥', 'æ•´æ²»'],
            'ç§‘æŠ€': ['äººå·¥æ™ºèƒ½', 'ai', 'å¤§æ•°æ®', 'äº‘è®¡ç®—', 'åŒºå—é“¾', 'èŠ¯ç‰‡', 'åŠå¯¼ä½“'],
        }

        # æ£€æŸ¥æ¯ä¸ªåˆ†ç±»
        text_to_check = f"{title} {summary}"
        for category, keywords in category_keywords.items():
            for keyword in keywords:
                if keyword in text_to_check:
                    return category

        return 'å…¶ä»–'

    def _calculate_importance(self, item) -> int:
        """è®¡ç®—æ–°é—»é‡è¦æ€§åˆ†æ•°ï¼ˆ1-10åˆ†ï¼‰"""
        score = 5  # åŸºç¡€åˆ†

        title = item.get('title', '')
        summary = item.get('summary', '')

        # ç´§æ€¥å…³é”®è¯åŠ åˆ†
        urgent_keywords = ['ç´§æ€¥', 'çªå‘', 'é‡ç£…', 'é‡å¤§', 'é¢„è­¦', 'è­¦æŠ¥', 'å±æœº', 'å´©ç›˜', 'æš´è·Œ', 'æš´æ¶¨']
        for keyword in urgent_keywords:
            if keyword in title:
                score += 2
                break

        # æ¶‰åŠè‚¡ç¥¨æ•°é‡åŠ åˆ†
        stock_list = item.get('stockList', [])
        if len(stock_list) > 0:
            score += min(len(stock_list) * 0.5, 3)

        # è¯„è®ºæ•°åŠ åˆ†
        comment_count = item.get('pinglun_Num', 0)
        if comment_count > 10:
            score += 1
        if comment_count > 50:
            score += 1

        # ç¡®ä¿åˆ†æ•°åœ¨1-10ä¹‹é—´
        return max(1, min(10, int(score)))

    def _judge_sentiment(self, text) -> str:
        """åˆ¤æ–­æƒ…æ„Ÿå€¾å‘"""
        text_lower = text.lower()

        bullish_keywords = ['ä¸Šæ¶¨', 'çœ‹å¥½', 'çªç ´', 'åˆ©å¥½', 'å¢é•¿', 'å¤è‹', 'æ‰©å¼ ', 'ä¹°å…¥', 'æ¨è', 'è¶…é¢„æœŸ']
        bearish_keywords = ['ä¸‹è·Œ', 'çœ‹ç©º', 'è·Œç ´', 'åˆ©ç©º', 'ä¸‹æ»‘', 'è¡°é€€', 'æ”¶ç¼©', 'å–å‡º', 'é¢„è­¦', 'ä¸åŠé¢„æœŸ']

        bullish_count = sum(1 for word in bullish_keywords if word in text_lower)
        bearish_count = sum(1 for word in bearish_keywords if word in text_lower)

        if bullish_count > bearish_count:
            return 'bullish'
        elif bearish_count > bullish_count:
            return 'bearish'
        else:
            return 'neutral'

    def _clean_news_item(self, news_item):
        """æ¸…ç†å’Œæ ‡å‡†åŒ–æ–°é—»æ•°æ®"""
        # ç¡®ä¿æ ‡é¢˜å’Œå†…å®¹ä¸ä¸ºç©º
        if not news_item.get('title'):
            news_item['title'] = 'æ— æ ‡é¢˜æ–°é—»'

        if not news_item.get('content'):
            news_item['content'] = news_item['title']

        if not news_item.get('full_content'):
            news_item['full_content'] = news_item['content']

        # æˆªæ–­è¿‡é•¿çš„å­—æ®µ
        max_title_len = 200
        max_content_len = 5000

        if len(news_item['title']) > max_title_len:
            news_item['title'] = news_item['title'][:max_title_len] + '...'

        if len(news_item['content']) > max_content_len:
            news_item['content'] = news_item['content'][:max_content_len] + '...'

        if len(news_item['full_content']) > max_content_len:
            news_item['full_content'] = news_item['full_content'][:max_content_len] + '...'

    def test_collection(self):
        """æµ‹è¯•é‡‡é›†åŠŸèƒ½"""
        print("=" * 60)
        print("ä¸œæ–¹è´¢å¯Œå¿«è®¯é‡‡é›†å™¨æµ‹è¯•")
        print("=" * 60)

        print(f"\nå°è¯•æŠ“å– 10 æ¡æ–°é—»...")
        news_list = self.fetch_news(page_size=10)

        if news_list:
            print(f"âœ… æˆåŠŸé‡‡é›†åˆ° {len(news_list)} æ¡æ–°é—»!")
            print("-" * 50)

            # æ˜¾ç¤ºæ‰€æœ‰æ–°é—»æ ‡é¢˜
            for i, news in enumerate(news_list[:5], 1):
                time_str = news.get('time', 'N/A')
                title = news.get('title', 'æ— æ ‡é¢˜')[:60]
                source = news.get('source', 'N/A')
                print(f"{i:2d}. [{time_str}] {title}... (æ¥æº: {source})")

            if len(news_list) > 5:
                print(f"... è¿˜æœ‰ {len(news_list) - 5} æ¡æœªæ˜¾ç¤º")

            # éªŒè¯æ•°æ®è´¨é‡
            self._validate_data(news_list)
            return True
        else:
            print("âŒ é‡‡é›†å¤±è´¥")
            return False

    def _validate_data(self, news_list):
        """éªŒè¯æ•°æ®è´¨é‡"""
        print("\næ•°æ®è´¨é‡æ£€æŸ¥:")
        print("-" * 30)

        total = len(news_list)
        if total == 0:
            print("âŒ æ²¡æœ‰é‡‡é›†åˆ°ä»»ä½•æ–°é—»")
            return

        # ç»Ÿè®¡å­—æ®µå®Œæ•´æ€§
        fields = ['title', 'content', 'full_content', 'time', 'source']
        stats = {}

        for field in fields:
            count = sum(1 for news in news_list if news.get(field))
            stats[field] = count

        print(f"æ–°é—»æ€»æ•°: {total}")
        for field, count in stats.items():
            percentage = (count / total) * 100
            status = "âœ…" if percentage > 80 else "âš ï¸" if percentage > 50 else "âŒ"
            print(f"{status} {field}: {count}/{total} ({percentage:.1f}%)")

        # æ£€æŸ¥å†…å®¹é•¿åº¦
        avg_content_len = sum(len(news.get('content', '')) for news in news_list) / total
        print(f"å¹³å‡å†…å®¹é•¿åº¦: {avg_content_len:.1f} å­—ç¬¦")


# ä¸»å‡½æ•° - ç›´æ¥è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    print("ä¸œæ–¹è´¢å¯Œå¿«è®¯é‡‡é›†å™¨ v3.0")
    print("ä¼˜åŒ–ç‰ˆ - ç›´æ¥åœ¨æ¶ˆæ¯ä¸­æ˜¾ç¤ºå†…å®¹")
    print()

    collector = EastMoneyCollector()
    success = collector.test_collection()

    print("\n" + "=" * 60)
    if success:
        print("âœ… é‡‡é›†å™¨æµ‹è¯•æˆåŠŸï¼")
        print("\nğŸ‰ ç³»ç»Ÿç‰¹ç‚¹:")
        print("1. âœ… ç›´æ¥æ˜¾ç¤ºæ–°é—»å†…å®¹ï¼Œæ— éœ€ç‚¹å‡»é“¾æ¥")
        print("2. âœ… åŒ…å«é‡è¦æ€§è¯„åˆ†å’Œæƒ…æ„Ÿåˆ†æ")
        print("3. âœ… æ•°æ®å®Œæ•´ï¼Œé€‚åˆé’‰é’‰æ¨é€")
    else:
        print("âŒ é‡‡é›†å™¨æµ‹è¯•å¤±è´¥")