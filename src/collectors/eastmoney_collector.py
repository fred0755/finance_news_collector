import requests
import json
import time
from datetime import datetime
from typing import List, Dict, Optional
import hashlib


class EastMoneyCollector:
    """ä¸œæ–¹è´¢å¯Œå¿«è®¯é‡‡é›†å™¨ï¼ˆä½¿ç”¨çœŸå®APIï¼‰"""

    def __init__(self):
        # æ‚¨æ‰¾åˆ°çš„çœŸå®APIåœ°å€
        self.base_url = "https://np-weblist.eastmoney.com/comm/web/getFastNewsList"

        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://kuaixun.eastmoney.com/',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        }

        # æ ¹æ®æ‚¨æˆªå›¾ä¸­çš„å‚æ•°æ„å»º
        self.base_params = {
            'client': 'web',
            'biz': 'web_724',
            'fastColumn': '102',  # å¿«è®¯æ ç›®ID
            'pageSize': 20,  # æ¯é¡µæ¡æ•°
            'sortEnd': int(time.time() * 1000000),  # å¾®ç§’æ—¶é—´æˆ³
            'req_trace': int(time.time() * 1000),  # æ¯«ç§’æ—¶é—´æˆ³
            '_': int(time.time() * 1000),
            'callback': f'jQuery_{int(time.time() * 1000)}'
        }

    def fetch_news(self, page_size: int = 20) -> Optional[List[Dict]]:
        """
        è·å–ä¸œæ–¹è´¢å¯Œå¿«è®¯æ–°é—»

        Args:
            page_size: æ¯é¡µæ•°é‡

        Returns:
            ç»“æ„åŒ–çš„æ–°é—»åˆ—è¡¨
        """
        try:
            # æ›´æ–°å‚æ•°
            params = self.base_params.copy()
            params['pageSize'] = page_size
            params['sortEnd'] = int(time.time() * 1000000)
            params['_'] = int(time.time() * 1000)
            params['callback'] = f'jQuery_{int(time.time() * 1000)}'

            print(f"æ­£åœ¨æŠ“å–å¿«è®¯ï¼Œæ¯é¡µ {page_size} æ¡...")
            print(f"API URL: {self.base_url}")

            response = requests.get(
                self.base_url,
                params=params,
                headers=self.headers,
                timeout=15
            )

            response.raise_for_status()
            print(f"HTTPçŠ¶æ€ç : {response.status_code}")

            # å¤„ç†JSONPå“åº”
            raw_text = response.text
            print(f"åŸå§‹å“åº”é•¿åº¦: {len(raw_text)} å­—ç¬¦")

            # æå–JSONéƒ¨åˆ†ï¼ˆJSONPæ ¼å¼ï¼šcallback({...})ï¼‰
            json_start = raw_text.find('(')
            json_end = raw_text.rfind(')')

            if json_start != -1 and json_end != -1:
                json_str = raw_text[json_start + 1:json_end]
                data = json.loads(json_str)
                print(f"æˆåŠŸè§£æJSONæ•°æ®")

                # è§£ææ–°é—»æ•°æ®
                news_list = self._parse_news_data(data)
                return news_list
            else:
                print(f"å“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONPæ ¼å¼")
                print(f"å“åº”é¢„è§ˆ: {raw_text[:200]}...")
                return None

        except requests.exceptions.RequestException as e:
            print(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
            return None
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {raw_text[:500]}...")
            return None
        except Exception as e:
            print(f"æœªçŸ¥é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _parse_news_data(self, data: Dict) -> List[Dict]:
        """
        è§£æAPIè¿”å›çš„æ–°é—»æ•°æ®

        æ ¹æ®ä¸œæ–¹è´¢å¯ŒAPIçš„å®é™…æ•°æ®ç»“æ„è¿›è¡Œè§£æ
        """
        news_items = []

        print(f"APIè¿”å›æ•°æ®é”®å: {list(data.keys())}")

        # æ ¹æ®å¸¸è§çš„APIç»“æ„æŸ¥æ‰¾æ–°é—»æ•°æ®
        # å¯èƒ½çš„æ•°æ®ç»“æ„ï¼šdataå­—æ®µã€resultå­—æ®µæˆ–ç›´æ¥æ˜¯æ•°ç»„
        if isinstance(data, dict):
            # å°è¯•ä¸åŒçš„æ•°æ®ä½ç½®
            data_locations = ['data', 'result', 'list', 'news']

            news_data = None
            for location in data_locations:
                if location in data:
                    news_data = data[location]
                    print(f"æ‰¾åˆ°æ–°é—»æ•°æ®åœ¨ '{location}' å­—æ®µ")
                    break

            # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šå­—æ®µï¼Œå°è¯•dataæœ¬èº«
            if news_data is None:
                news_data = data
        elif isinstance(data, list):
            news_data = data
            print(f"APIç›´æ¥è¿”å›åˆ—è¡¨ï¼Œé•¿åº¦: {len(news_data)}")
        else:
            print(f"æœªçŸ¥çš„æ•°æ®ç±»å‹: {type(data)}")
            return news_items

        # å¤„ç†æ–°é—»æ•°æ®
        if isinstance(news_data, list):
            print(f"å¼€å§‹è§£æ {len(news_data)} æ¡æ–°é—»...")

            for i, item in enumerate(news_data):
                try:
                    # è§£æå•æ¡æ–°é—»
                    news_item = self._parse_single_news(item)
                    if news_item and news_item.get('title'):
                        news_items.append(news_item)

                        # åªæ˜¾ç¤ºå‰3æ¡ä½œä¸ºç¤ºä¾‹
                        if i < 3:
                            print(f"  ç¤ºä¾‹{i + 1}: {news_item['title'][:50]}...")

                except Exception as e:
                    print(f"è§£æç¬¬{i + 1}æ¡æ–°é—»å¤±è´¥: {e}")
                    continue

        elif isinstance(news_data, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼Œå¯èƒ½åŒ…å«åˆ†é¡µä¿¡æ¯
            print(f"æ–°é—»æ•°æ®æ˜¯å­—å…¸ï¼Œé”®å: {list(news_data.keys())}")

            # å°è¯•åœ¨å­—å…¸ä¸­æŸ¥æ‰¾åˆ—è¡¨
            for key, value in news_data.items():
                if isinstance(value, list):
                    print(f"åœ¨ '{key}' ä¸­æ‰¾åˆ°åˆ—è¡¨æ•°æ®ï¼Œé•¿åº¦: {len(value)}")
                    news_items.extend([self._parse_single_news(item) for item in value[:10]])
                    break
        else:
            print(f"æ— æ³•å¤„ç†çš„æ–°é—»æ•°æ®ç±»å‹: {type(news_data)}")

        return news_items

    def _parse_single_news(self, item) -> Dict:
        """è§£æå•æ¡æ–°é—» - ä¼˜åŒ–ç‰ˆï¼ˆæ ¹æ®å®é™…æ•°æ®ç»“æ„ï¼‰"""
        try:
            # ä¸ºæ–°é—»ç”Ÿæˆå”¯ä¸€IDï¼ˆä½¿ç”¨æ ‡é¢˜+æ—¶é—´çš„å“ˆå¸Œï¼‰
            unique_str = f"{item.get('title', '')}_{item.get('showTime', '')}_{item.get('code', '')}"
            news_id = hashlib.md5(unique_str.encode()).hexdigest()[:16]

            # åŸºç¡€æ–°é—»ç»“æ„
            news_item = {
                'id': news_id,
                'code': item.get('code', ''),  # æ–°é—»å”¯ä¸€ä»£ç 
                'raw_data': item  # ä¿å­˜åŸå§‹æ•°æ®
            }

            # 1. æ ‡é¢˜å’Œå†…å®¹ï¼ˆç›´æ¥ä»APIå­—æ®µæ˜ å°„ï¼‰
            news_item['title'] = item.get('title', '').strip()
            news_item['content'] = item.get('summary', '').strip()

            # å¦‚æœå†…å®¹ä¸ºç©ºï¼Œä½¿ç”¨æ ‡é¢˜ä½œä¸ºå†…å®¹
            if not news_item['content']:
                news_item['content'] = news_item['title']

            # 2. æ—¶é—´å­—æ®µï¼ˆå…³é”®ä¿®å¤ï¼‰
            # ä¼˜å…ˆä½¿ç”¨showTimeï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å½“å‰æ—¶é—´
            show_time = item.get('showTime', '')
            if show_time:
                # showTimeå·²ç»æ˜¯æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
                news_item['time'] = show_time
                news_item['publish_time'] = show_time

                # åŒæ—¶ä¿å­˜æ—¶é—´æˆ³æ ¼å¼ï¼ˆä¾¿äºæ’åºå’Œè®¡ç®—ï¼‰
                try:
                    # å°è¯•å°†å­—ç¬¦ä¸²æ—¶é—´è½¬ä¸ºæ—¶é—´æˆ³
                    dt_obj = datetime.strptime(show_time, '%Y-%m-%d %H:%M:%S')
                    news_item['timestamp'] = int(dt_obj.timestamp())
                except:
                    news_item['timestamp'] = int(time.time())
            else:
                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                news_item['time'] = current_time
                news_item['publish_time'] = current_time
                news_item['timestamp'] = int(time.time())

            # 3. æ¥æºå¤„ç†ï¼ˆä¸œæ–¹è´¢å¯Œå¿«è®¯å¯èƒ½æ²¡æœ‰æ˜ç¡®çš„å¤–éƒ¨æ¥æºï¼‰
            # å…ˆå°è¯•ä»å¯èƒ½çš„å­—æ®µè·å–ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
            source = item.get('mediaName', item.get('source', ''))
            if not source:
                # æ ¹æ®å†…å®¹åˆ¤æ–­å¯èƒ½çš„æ¥æº
                summary = item.get('summary', '')
                if 'ç»¼åˆè¿è¾“æ˜¥è¿å·¥ä½œä¸“ç­æ•°æ®' in summary:
                    source = 'äº¤é€šè¿è¾“éƒ¨'
                elif 'å¤®è¡Œ' in summary or 'è´§å¸æ”¿ç­–' in summary:
                    source = 'ä¸­å›½äººæ°‘é“¶è¡Œ'
                elif 'è¯ç›‘ä¼š' in summary or 'ä¸Šäº¤æ‰€' in summary or 'æ·±äº¤æ‰€' in summary:
                    source = 'è¯ç›‘ä¼š/äº¤æ˜“æ‰€'
                else:
                    source = 'ä¸œæ–¹è´¢å¯Œå¿«è®¯'  # é»˜è®¤æ¥æº

            news_item['source'] = source.strip()

            # 4. å…¶ä»–å­—æ®µ
            news_item['url'] = f"https://kuaixun.eastmoney.com/news/{news_item['code']}.html"
            news_item['category'] = self._infer_category(item)
            news_item['importance'] = self._calculate_importance(item)

            # 5. è‚¡ç¥¨/æ¦‚å¿µå…³è”ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            stock_list = item.get('stockList', [])
            if stock_list and isinstance(stock_list, list):
                news_item['related_stocks'] = stock_list
                news_item['has_stock_mention'] = True
            else:
                news_item['related_stocks'] = []
                news_item['has_stock_mention'] = False

            # 6. äº’åŠ¨æ•°æ®
            news_item['comment_count'] = item.get('pinglun_Num', 0)
            news_item['share_count'] = item.get('share', 0)

            # 7. æ¸…ç†å’ŒéªŒè¯
            self._clean_news_item(news_item)

            return news_item

        except Exception as e:
            print(f"è§£æå•æ¡æ–°é—»å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            # è¿”å›æœ€å°å¯ç”¨çš„æ–°é—»å¯¹è±¡
            return {
                'id': hashlib.md5(str(time.time()).encode()).hexdigest()[:16],
                'title': str(item.get('title', 'è§£æå¤±è´¥'))[:200],
                'content': str(item)[:500],
                'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'source': 'è§£æå¼‚å¸¸',
                'url': '',
                'category': 'å…¶ä»–',
                'importance': 1
            }

    def _infer_category(self, item) -> str:
        """æ ¹æ®å†…å®¹æ¨æ–­æ–°é—»åˆ†ç±»"""
        title = item.get('title', '').lower()
        summary = item.get('summary', '').lower()

        # å…³é”®è¯åŒ¹é…åˆ†ç±»
        category_keywords = {
            'å®è§‚': ['gdp', 'cpi', 'ppi', 'é€šèƒ€', 'é€šç¼©', 'è´§å¸æ”¿ç­–', 'è´¢æ”¿æ”¿ç­–', 'å¤®è¡Œ', 'åˆ©ç‡', 'å­˜æ¬¾å‡†å¤‡é‡‘', 'mlf',
                     'slf', 'é€†å›è´­', 'ç»æµæ•°æ®', 'pmi', 'å·¥ä¸šå¢åŠ å€¼', 'å›ºå®šèµ„äº§æŠ•èµ„', 'æ¶ˆè´¹å“é›¶å”®æ€»é¢', 'å¤±ä¸šç‡',
                     'å¤–æ±‡å‚¨å¤‡', 'è´¸æ˜“é¡ºå·®', 'è´¸æ˜“é€†å·®', 'è¿›å‡ºå£'],
            'è‚¡å¸‚': ['aè‚¡', 'æ²ªæŒ‡', 'æ·±æŒ‡', 'åˆ›ä¸šæ¿', 'ç§‘åˆ›æ¿', 'åŒ—è¯', 'æ¶¨åœ', 'è·Œåœ', 'å¤§ç›˜', 'æŒ‡æ•°', 'è‚¡ç¥¨', 'è‚¡ä»·',
                     'å¸‚å€¼', 'å¸‚ç›ˆç‡', 'å¸‚å‡€ç‡', 'æ¢æ‰‹ç‡', 'æˆäº¤é‡', 'æˆäº¤é¢', 'ä¸»åŠ›èµ„é‡‘', 'åŒ—å‘èµ„é‡‘', 'å—å‘èµ„é‡‘',
                     'èèµ„èåˆ¸', 'ä¸¤è'],
            'å€ºåˆ¸': ['å›½å€º', 'åœ°æ–¹å€º', 'åŸæŠ•å€º', 'ä¼ä¸šå€º', 'å¯è½¬å€º', 'å€ºåˆ¸', 'æ”¶ç›Šç‡', 'åˆ©ç‡å€º', 'ä¿¡ç”¨å€º', 'å€ºå¸‚',
                     'åˆ°æœŸæ”¶ç›Šç‡', 'ä¹…æœŸ', 'å‡¸æ€§', 'ä¿¡ç”¨åˆ©å·®', 'è¯„çº§'],
            'æœŸè´§': ['æœŸè´§', 'åŸæ²¹', 'é»„é‡‘', 'ç™½é“¶', 'é“œ', 'é“', 'é”Œ', 'é“…', 'é•', 'é”¡', 'èºçº¹é’¢', 'é“çŸ¿çŸ³', 'ç„¦ç…¤',
                     'ç„¦ç‚­', 'åŠ¨åŠ›ç…¤', 'å¤©ç„¶æ©¡èƒ¶', 'æ£‰èŠ±', 'ç™½ç³–', 'è±†ç²•', 'è±†æ²¹', 'æ£•æ¦ˆæ²¹', 'ç‰ç±³', 'é¸¡è›‹', 'ç”ŸçŒª',
                     'è‹¹æœ'],
            'å¤–æ±‡': ['ç¾å…ƒ', 'äººæ°‘å¸', 'æ¬§å…ƒ', 'è‹±é•‘', 'æ—¥å…ƒ', 'æ¾³å…ƒ', 'åŠ å…ƒ', 'ç‘éƒ', 'æ±‡ç‡', 'å¤–æ±‡', 'ä¸­é—´ä»·', 'åœ¨å²¸',
                     'ç¦»å²¸', 'cfets', 'ä¸€ç¯®å­è´§å¸'],
            'å•†å“': ['åŸæ²¹', 'é»„é‡‘', 'ç™½é“¶', 'é“œ', 'é“', 'é”Œ', 'é“…', 'é•', 'é”¡', 'èºçº¹é’¢', 'é“çŸ¿çŸ³', 'ç„¦ç…¤', 'ç„¦ç‚­',
                     'åŠ¨åŠ›ç…¤', 'å¤©ç„¶æ©¡èƒ¶', 'æ£‰èŠ±', 'ç™½ç³–', 'è±†ç²•', 'è±†æ²¹', 'æ£•æ¦ˆæ²¹', 'ç‰ç±³', 'é¸¡è›‹', 'ç”ŸçŒª', 'è‹¹æœ',
                     'å¤§å®—å•†å“', 'ç°è´§', 'å•†å“'],
            'ç†è´¢': ['é“¶è¡Œç†è´¢', 'ä¿¡æ‰˜', 'ä¿é™©', 'åŸºé‡‘', 'èµ„ç®¡', 'ç†è´¢äº§å“', 'æ”¶ç›Šç‡', 'å‡€å€¼', 'ç”³è´­', 'èµå›', 'å¼€æ”¾æœŸ',
                     'å°é—­æœŸ'],
            'æˆ¿åœ°äº§': ['æˆ¿ä»·', 'æˆ¿åœ°äº§', 'æ¥¼å¸‚', 'æˆ¿ä¼', 'åœŸåœ°', 'æ‹å–', 'æˆäº¤', 'é”€å”®', 'æŠ•èµ„', 'å¼€å‘', 'ä½å®…', 'å•†ä¸š',
                       'åŠå…¬', 'ç§Ÿèµ', 'ç§Ÿé‡‘', 'ç©ºç½®ç‡', 'å»åŒ–å‘¨æœŸ'],
            'å…¬å¸': ['è´¢æŠ¥', 'ä¸šç»©', 'è¥æ”¶', 'å‡€åˆ©æ¶¦', 'æ¯›åˆ©ç‡', 'å‡€åˆ©ç‡', 'roe', 'roa', 'è´Ÿå€ºç‡', 'ç°é‡‘æµ', 'åˆ†çº¢',
                     'é€è½¬', 'å›è´­', 'å¢æŒ', 'å‡æŒ', 'è´¨æŠ¼', 'å†»ç»“', 'è¯‰è®¼', 'ä»²è£', 'å¤„ç½š', 'st', '*st', 'é€€å¸‚',
                     'ä¸Šå¸‚', 'ipo', 'å†èèµ„', 'å®šå¢', 'é…è‚¡', 'å¯è½¬å€º', 'å‘å€º'],
            'è¡Œä¸š': ['è¡Œä¸š', 'æ¿å—', 'æ¦‚å¿µ', 'ä¸»é¢˜', 'äº§ä¸šé“¾', 'ä¾›åº”é“¾', 'ä¸Šä¸‹æ¸¸', 'äº§èƒ½', 'äº§é‡', 'é”€é‡', 'åº“å­˜',
                     'ä»·æ ¼', 'æˆæœ¬', 'åˆ©æ¶¦', 'ç«äº‰', 'å„æ–­', 'é›†ä¸­åº¦', 'å¸‚åœºä»½é¢', 'é¾™å¤´', 'ä¸­å°ä¼ä¸š'],
            'å›½é™…': ['ç¾è”å‚¨', 'æ¬§å¤®è¡Œ', 'æ—¥å¤®è¡Œ', 'è‹±å¤®è¡Œ', 'æ¾³æ´²è”å‚¨', 'åŠ æ‹¿å¤§å¤®è¡Œ', 'ç‘å£«å¤®è¡Œ', 'åŠ æ¯', 'é™æ¯', 'qe',
                     'qt', 'ç¼©è¡¨', 'é€šèƒ€ç›®æ ‡', 'å°±ä¸šæ•°æ®', 'è´¸æ˜“æ•°æ®', 'ç»æµæ•°æ®', 'åœ°ç¼˜æ”¿æ²»', 'æˆ˜äº‰', 'å†²çª', 'åˆ¶è£',
                     'å…³ç¨', 'è´¸æ˜“æˆ˜', 'ç§‘æŠ€æˆ˜', 'é‡‘èæˆ˜'],
            'æ”¿ç­–': ['æ”¿ç­–', 'æ³•è§„', 'æ¡ä¾‹', 'åŠæ³•', 'é€šçŸ¥', 'å…¬å‘Š', 'æ„è§', 'è§„åˆ’', 'è®¡åˆ’', 'æ–¹æ¡ˆ', 'æªæ–½', 'æŒ‡å¯¼æ„è§',
                     'å®æ–½ç»†åˆ™', 'ç›‘ç®¡', 'æ£€æŸ¥', 'æ•´æ²»', 'æ•´é¡¿', 'æ¸…ç†', 'è§„èŒƒ', 'æ ‡å‡†', 'å‡†å…¥', 'è®¸å¯', 'å¤‡æ¡ˆ', 'å®¡æ‰¹',
                     'æ ¸å‡†', 'ç™»è®°', 'æ³¨å†Œ'],
            'ç§‘æŠ€': ['äººå·¥æ™ºèƒ½', 'ai', 'å¤§æ•°æ®', 'äº‘è®¡ç®—', 'åŒºå—é“¾', 'æ•°å­—è´§å¸', 'å…ƒå®‡å®™', 'ç‰©è”ç½‘', '5g', '6g', 'èŠ¯ç‰‡',
                     'åŠå¯¼ä½“', 'é›†æˆç”µè·¯', 'å…‰åˆ»æœº', 'æ“ä½œç³»ç»Ÿ', 'æ•°æ®åº“', 'ä¸­é—´ä»¶', 'åº”ç”¨è½¯ä»¶', 'ç½‘ç»œå®‰å…¨', 'ä¿¡æ¯å®‰å…¨',
                     'æ•°æ®å®‰å…¨', 'éšç§ä¿æŠ¤', 'ç®—æ³•', 'æ¨¡å‹', 'ç®—åŠ›', 'æ•°æ®'],
        }

        # æ£€æŸ¥æ¯ä¸ªåˆ†ç±»
        text_to_check = f"{title} {summary}"
        for category, keywords in category_keywords.items():
            for keyword in keywords:
                if keyword in text_to_check:
                    return category

        return 'å…¶ä»–'

    def _calculate_importance(self, item) -> int:
        """è®¡ç®—æ–°é—»é‡è¦æ€§åˆ†æ•°ï¼ˆ1-10åˆ†ï¼‰"""
        score = 5  # åŸºç¡€åˆ†

        title = item.get('title', '')
        summary = item.get('summary', '')

        # ç´§æ€¥å…³é”®è¯åŠ åˆ†
        urgent_keywords = ['ç´§æ€¥', 'çªå‘', 'é‡ç£…', 'é‡å¤§', 'é¢„è­¦', 'è­¦æŠ¥', 'å±æœº', 'å´©ç›˜', 'æš´è·Œ', 'æš´æ¶¨', 'ç ´ä½',
                           'çªç ´', 'å†å²', 'é¦–æ¬¡', 'çºªå½•', 'æ–°é«˜', 'æ–°ä½']
        for keyword in urgent_keywords:
            if keyword in title:
                score += 2
                break

        # æ¶‰åŠè‚¡ç¥¨æ•°é‡åŠ åˆ†
        stock_list = item.get('stockList', [])
        if len(stock_list) > 0:
            score += min(len(stock_list) * 0.5, 3)  # æœ€å¤šåŠ 3åˆ†

        # è¯„è®ºæ•°åŠ åˆ†
        comment_count = item.get('pinglun_Num', 0)
        if comment_count > 10:
            score += 1
        if comment_count > 50:
            score += 1

        # ç¡®ä¿åˆ†æ•°åœ¨1-10ä¹‹é—´
        return max(1, min(10, int(score)))

    def _clean_news_item(self, news_item):
        """æ¸…ç†å’Œæ ‡å‡†åŒ–æ–°é—»æ•°æ®"""
        # ç¡®ä¿æ ‡é¢˜å’Œå†…å®¹ä¸ä¸ºç©º
        if not news_item.get('title'):
            news_item['title'] = 'æ— æ ‡é¢˜æ–°é—»'

        if not news_item.get('content'):
            news_item['content'] = news_item['title']

        # æˆªæ–­è¿‡é•¿çš„å­—æ®µ
        max_title_len = 200
        max_content_len = 5000

        if len(news_item['title']) > max_title_len:
            news_item['title'] = news_item['title'][:max_title_len] + '...'

        if len(news_item['content']) > max_content_len:
            news_item['content'] = news_item['content'][:max_content_len] + '...'

    def test_collection(self):
        """æµ‹è¯•é‡‡é›†åŠŸèƒ½"""
        print("=" * 60)
        print("ä¸œæ–¹è´¢å¯Œå¿«è®¯é‡‡é›†å™¨æµ‹è¯•ï¼ˆä½¿ç”¨çœŸå®APIï¼‰")
        print("=" * 60)

        # å°è¯•æŠ“å–ä¸åŒæ•°é‡çš„æ–°é—»è¿›è¡Œæµ‹è¯•
        for page_size in [5, 10, 20]:
            print(f"\nå°è¯•æŠ“å– {page_size} æ¡æ–°é—»...")
            news_list = self.fetch_news(page_size=page_size)

            if news_list:
                print(f"âœ… æˆåŠŸé‡‡é›†åˆ° {len(news_list)} æ¡æ–°é—»!")
                print("-" * 50)

                # æ˜¾ç¤ºæ‰€æœ‰æ–°é—»æ ‡é¢˜
                for i, news in enumerate(news_list[:10], 1):
                    time_str = news.get('time', 'N/A')
                    title = news.get('title', 'æ— æ ‡é¢˜')[:60]
                    source = news.get('source', 'N/A')
                    print(f"{i:2d}. [{time_str}] {title}... (æ¥æº: {source})")

                if len(news_list) > 10:
                    print(f"... è¿˜æœ‰ {len(news_list) - 10} æ¡æœªæ˜¾ç¤º")

                # ä¿å­˜è¯¦ç»†æ•°æ®ç”¨äºåˆ†æ
                self._save_debug_data(news_list)

                # éªŒè¯æ•°æ®è´¨é‡
                self._validate_data(news_list)
                return True
            else:
                print(f"âŒ é‡‡é›† {page_size} æ¡å¤±è´¥ï¼Œå°è¯•è°ƒæ•´å‚æ•°...")

        print("\næ‰€æœ‰å°è¯•å‡å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–APIå‚æ•°")
        return False

    def _save_debug_data(self, news_list):
        """ä¿å­˜è°ƒè¯•æ•°æ®"""
        if news_list:
            # ä¿å­˜ç¬¬ä¸€æ¡æ–°é—»çš„å®Œæ•´æ•°æ®
            debug_data = {
                'total_count': len(news_list),
                'sample_news': news_list[0] if news_list else {},
                'all_titles': [news.get('title', '') for news in news_list]
            }

            with open('debug_eastmoney_news.json', 'w', encoding='utf-8') as f:
                json.dump(debug_data, f, ensure_ascii=False, indent=2)

            print(f"\nè°ƒè¯•æ•°æ®å·²ä¿å­˜åˆ°: debug_eastmoney_news.json")

            # ä¹Ÿä¿å­˜åŸå§‹å“åº”ç”¨äºåˆ†æ
            if news_list and 'raw_data' in news_list[0]:
                with open('debug_raw_response.json', 'w', encoding='utf-8') as f:
                    json.dump(news_list[0]['raw_data'], f, ensure_ascii=False, indent=2)
                print(f"åŸå§‹å“åº”æ•°æ®å·²ä¿å­˜åˆ°: debug_raw_response.json")

    def _validate_data(self, news_list):
        """éªŒè¯æ•°æ®è´¨é‡"""
        print("\næ•°æ®è´¨é‡æ£€æŸ¥:")
        print("-" * 30)

        total = len(news_list)
        if total == 0:
            print("âŒ æ²¡æœ‰é‡‡é›†åˆ°ä»»ä½•æ–°é—»")
            return

        # ç»Ÿè®¡å­—æ®µå®Œæ•´æ€§
        fields = ['title', 'content', 'time', 'source']
        stats = {}

        for field in fields:
            count = sum(1 for news in news_list if news.get(field))
            stats[field] = count

        print(f"æ–°é—»æ€»æ•°: {total}")
        for field, count in stats.items():
            percentage = (count / total) * 100
            status = "âœ…" if percentage > 80 else "âš ï¸" if percentage > 50 else "âŒ"
            print(f"{status} {field}: {count}/{total} ({percentage:.1f}%)")

        # æ£€æŸ¥æ ‡é¢˜é•¿åº¦
        avg_title_len = sum(len(news.get('title', '')) for news in news_list) / total
        print(f"å¹³å‡æ ‡é¢˜é•¿åº¦: {avg_title_len:.1f} å­—ç¬¦")

        if avg_title_len < 5:
            print("âš ï¸ è­¦å‘Š: å¹³å‡æ ‡é¢˜é•¿åº¦è¿‡çŸ­ï¼Œå¯èƒ½æ•°æ®è§£ææœ‰è¯¯")


# ä¸»å‡½æ•° - ç›´æ¥è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    print("ä¸œæ–¹è´¢å¯Œå¿«è®¯é‡‡é›†å™¨ v2.0")
    print("åŸºäºçœŸå®API: https://np-weblist.eastmoney.com/comm/web/getFastNewsList")
    print()

    collector = EastMoneyCollector()
    success = collector.test_collection()

    print("\n" + "=" * 60)
    if success:
        print("âœ… é‡‡é›†å™¨æµ‹è¯•æˆåŠŸï¼")
        print("\nğŸ‰ æ­å–œï¼æ‚¨å·²æˆåŠŸå®Œæˆï¼š")
        print("1. âœ… æ‰¾åˆ°ä¸œæ–¹è´¢å¯ŒçœŸå®å¿«è®¯API")
        print("2. âœ… å®ç°å¯å·¥ä½œçš„é‡‡é›†å™¨")
        print("3. âœ… è·å–ç»“æ„åŒ–æ–°é—»æ•°æ®")

        print("\nğŸ“‹ ä¸‹ä¸€æ­¥è®¡åˆ’ï¼ˆM1.1 å®Œæˆåçš„åç»­æ­¥éª¤ï¼‰:")
        print("1. é›†æˆè°ƒåº¦å™¨ï¼ˆAPSchedulerï¼‰å®ç°å®šæ—¶é‡‡é›†")
        print("2. è®¾è®¡æ•°æ®åº“è¡¨ç»“æ„å¹¶å®ç°å­˜å‚¨")
        print("3. æ·»åŠ åŸºç¡€å»é‡åŠŸèƒ½ï¼ˆURLå“ˆå¸Œï¼‰")
        print("4. åˆ›å»ºç®€å•çš„å‘½ä»¤è¡Œç®¡ç†ç•Œé¢")
    else:
        print("âŒ é‡‡é›†å™¨æµ‹è¯•å¤±è´¥")
        print("\nğŸ”§ è°ƒè¯•å»ºè®®:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. æ£€æŸ¥APIå‚æ•°æ˜¯å¦è¿‡æœŸ")
        print("3. æŸ¥çœ‹ç”Ÿæˆçš„è°ƒè¯•æ–‡ä»¶åˆ†ææ•°æ®ç»“æ„")
        print("4. å°è¯•åœ¨æµè§ˆå™¨ä¸­ç›´æ¥è®¿é—®APIé“¾æ¥æµ‹è¯•")