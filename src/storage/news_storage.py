# src/storage/news_storage.py
import sqlite3
import json
import logging
from datetime import datetime
from typing import List, Dict, Optional

logger = logging.getLogger(__name__)


class NewsStorage:
    def __init__(self, db_path: str = None):
        """
        åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨

        Args:
            db_path: SQLiteæ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨å®šä½åˆ°é¡¹ç›®æ ¹ç›®å½•çš„finance_news.db
        """
        if db_path is None:
            # è‡ªåŠ¨å®šä½åˆ°é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„finance_news.db
            import os
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
            current_dir = os.path.dirname(os.path.abspath(__file__))  # src/storage/
            # å‘ä¸Šä¸¤çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
            project_root = os.path.dirname(os.path.dirname(current_dir))  # é¡¹ç›®æ ¹ç›®å½•
            # æ„å»ºå®Œæ•´è·¯å¾„
            db_path = os.path.join(project_root, 'finance_news.db')

        self.db_path = db_path
        print(f"ğŸ“ æ•°æ®åº“æ–‡ä»¶è·¯å¾„: {self.db_path}")  # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ“ æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(self.db_path)}")  # æ£€æŸ¥æ–‡ä»¶
        self._init_connection()

    def _init_connection(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            self.conn = sqlite3.connect(self.db_path)
            # å¯ç”¨å¤–é”®æ”¯æŒ
            self.conn.execute("PRAGMA foreign_keys = ON")
            # è®¾ç½®è¿”å›å­—å…¸æ ¼å¼çš„æ¸¸æ ‡
            self.conn.row_factory = sqlite3.Row
            logger.info(f"å·²è¿æ¥åˆ°æ•°æ®åº“: {self.db_path}")
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise

    def save_news_batch(self, news_list: List[Dict]) -> Dict:
        """
        æ‰¹é‡ä¿å­˜æ–°é—»æ•°æ®ï¼Œè‡ªåŠ¨å»é‡

        Args:
            news_list: æ–°é—»å­—å…¸åˆ—è¡¨

        Returns:
            ç»Ÿè®¡ä¿¡æ¯: {'total': æ€»æ•°, 'saved': ä¿å­˜æ•°, 'duplicates': é‡å¤æ•°}
        """
        if not news_list:
            return {'total': 0, 'saved': 0, 'duplicates': 0}

        stats = {'total': len(news_list), 'saved': 0, 'duplicates': 0}

        try:
            cursor = self.conn.cursor()

            for news in news_list:
                # 1. æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŸºäºnews_codeå»é‡ï¼‰
                news_code = news.get('code', '')
                if not news_code:
                    # å¦‚æœæ²¡æœ‰codeï¼Œä½¿ç”¨æ ‡é¢˜+æ—¶é—´çš„å“ˆå¸Œ
                    import hashlib
                    unique_str = f"{news.get('title', '')}_{news.get('publish_time', '')}"
                    news_code = hashlib.md5(unique_str.encode()).hexdigest()[:16]
                    news['code'] = news_code

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                cursor.execute(
                    "SELECT id FROM news_articles WHERE news_code = ?",
                    (news_code,)
                )
                existing = cursor.fetchone()

                if existing:
                    stats['duplicates'] += 1
                    logger.debug(f"è·³è¿‡é‡å¤æ–°é—»: {news.get('title', '')[:50]}...")
                    continue

                # 2. å‡†å¤‡æ’å…¥æ•°æ®
                # å¤„ç†ç›¸å…³è‚¡ç¥¨åˆ—è¡¨ï¼ˆåˆ—è¡¨è½¬JSONå­—ç¬¦ä¸²ï¼‰
                related_stocks = news.get('related_stocks', [])
                if isinstance(related_stocks, list):
                    related_stocks_json = json.dumps(related_stocks, ensure_ascii=False)
                else:
                    related_stocks_json = '[]'

                # å¤„ç†å‘å¸ƒæ—¶é—´
                publish_time = news.get('publish_time', '')
                if not publish_time:
                    publish_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

                # 3. æ’å…¥æ–°é—»æ•°æ®
                cursor.execute('''
                INSERT INTO news_articles (
                    news_code, title, content, source, publish_time,
                    category, importance, url, has_stock_mention, related_stocks
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    news_code,
                    news.get('title', '')[:500],  # é™åˆ¶æ ‡é¢˜é•¿åº¦
                    news.get('content', ''),
                    news.get('source', 'ä¸œæ–¹è´¢å¯Œ'),
                    publish_time,
                    news.get('category', 'å…¶ä»–'),
                    news.get('importance', 5),
                    news.get('url', ''),
                    1 if news.get('has_stock_mention', False) else 0,
                    related_stocks_json
                ))

                news_id = cursor.lastrowid

                # 4. è®°å½•å»é‡å“ˆå¸Œ
                cursor.execute(
                    "INSERT INTO news_deduplication (news_code_hash, news_id) VALUES (?, ?)",
                    (news_code, news_id)
                )

                stats['saved'] += 1
                logger.debug(f"ä¿å­˜æ–°é—»: {news.get('title', '')[:60]}...")

            # æäº¤äº‹åŠ¡
            self.conn.commit()
            logger.info(f"æ‰¹é‡ä¿å­˜å®Œæˆ: æ€»æ•°={stats['total']}, æ–°å¢={stats['saved']}, é‡å¤={stats['duplicates']}")

            return stats

        except Exception as e:
            self.conn.rollback()
            logger.error(f"æ‰¹é‡ä¿å­˜å¤±è´¥: {e}")
            raise

    def get_recent_news(self, limit: int = 20) -> List[Dict]:
        """
        è·å–æœ€è¿‘æ–°é—»

        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            æ–°é—»å­—å…¸åˆ—è¡¨
        """
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                SELECT * FROM news_articles 
                ORDER BY publish_time DESC 
                LIMIT ?
            ''', (limit,))

            rows = cursor.fetchall()

            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            news_list = []
            for row in rows:
                news_dict = dict(row)
                # è§£ærelated_stocks JSONå­—ç¬¦ä¸²
                if news_dict.get('related_stocks'):
                    try:
                        news_dict['related_stocks'] = json.loads(news_dict['related_stocks'])
                    except:
                        news_dict['related_stocks'] = []
                news_list.append(news_dict)

            logger.debug(f"è·å–æœ€è¿‘ {len(news_list)} æ¡æ–°é—»")
            return news_list

        except Exception as e:
            logger.error(f"è·å–æ–°é—»å¤±è´¥: {e}")
            return []

    def get_news_count(self) -> int:
        """è·å–æ–°é—»æ€»æ•°"""
        try:
            cursor = self.conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM news_articles")
            return cursor.fetchone()[0]
        except Exception as e:
            logger.error(f"è·å–æ–°é—»æ€»æ•°å¤±è´¥: {e}")
            return 0

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")


# å•ä¾‹æ¨¡å¼ï¼ˆå¯é€‰ï¼‰
_global_storage = None


def get_storage() -> NewsStorage:
    """è·å–å…¨å±€å­˜å‚¨å®ä¾‹"""
    global _global_storage
    if _global_storage is None:
        _global_storage = NewsStorage()
    return _global_storage


def test_storage():
    """æµ‹è¯•å­˜å‚¨åŠŸèƒ½"""
    print("æµ‹è¯•æ–°é—»å­˜å‚¨åŠŸèƒ½...")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_news = [
        {
            'code': 'TEST001',
            'title': 'æµ‹è¯•æ–°é—»æ ‡é¢˜1',
            'content': 'æµ‹è¯•æ–°é—»å†…å®¹1',
            'source': 'æµ‹è¯•æ¥æº',
            'publish_time': '2026-02-03 10:00:00',
            'category': 'æµ‹è¯•',
            'importance': 7,
            'url': 'https://example.com/test1',
            'has_stock_mention': False,
            'related_stocks': []
        },
        {
            'code': 'TEST002',
            'title': 'æµ‹è¯•æ–°é—»æ ‡é¢˜2',
            'content': 'æµ‹è¯•æ–°é—»å†…å®¹2',
            'source': 'æµ‹è¯•æ¥æº',
            'publish_time': '2026-02-03 10:05:00',
            'category': 'æµ‹è¯•',
            'importance': 8,
            'url': 'https://example.com/test2',
            'has_stock_mention': True,
            'related_stocks': ['000001.SZ', '600000.SH']
        }
    ]

    storage = NewsStorage()

    # æµ‹è¯•ä¿å­˜
    print("1. æµ‹è¯•æ‰¹é‡ä¿å­˜...")
    stats = storage.save_news_batch(test_news)
    print(f"   ç»“æœ: {stats}")

    # æµ‹è¯•æŸ¥è¯¢
    print("2. æµ‹è¯•æŸ¥è¯¢æœ€è¿‘æ–°é—»...")
    recent_news = storage.get_recent_news(5)
    print(f"   è·å–åˆ° {len(recent_news)} æ¡æ–°é—»")
    for i, news in enumerate(recent_news):
        print(f"     {i + 1}. {news['title'][:40]}... ({news['publish_time']})")

    # æµ‹è¯•è®¡æ•°
    print("3. æµ‹è¯•æ–°é—»è®¡æ•°...")
    count = storage.get_news_count()
    print(f"   æ•°æ®åº“ä¸­å…±æœ‰ {count} æ¡æ–°é—»")

    storage.close()
    print("âœ… å­˜å‚¨æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    test_storage()